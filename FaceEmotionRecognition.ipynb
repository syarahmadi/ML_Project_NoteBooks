{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDuVptD45hJs",
        "outputId": "d48d8685-065a-4985-e27a-e5e54f60aadb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 26 01:45:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    27W /  70W |   2900MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# get info of colab GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQmdpkbk5WcO",
        "outputId": "1a3d15fc-07c7-4421-ade7-160cc27797f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# Check the GPU device is working\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4HMMNyXkdLF",
        "outputId": "6571e190-781a-44ed-b840-5d3e7d998ef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Access to the google drive where the data is stored\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "AMz4Aj1Z4Ke5"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential \n",
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from skimage import io\n",
        "import glob\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "V2L0bgBhdOSI"
      },
      "outputs": [],
      "source": [
        "from operator import concat\n",
        "#Define Paths\n",
        "data_train_path = Path('/content/drive/My Drive/data/FaceData/train')         # Define path for data\n",
        "data_test_path = Path('/content/drive/My Drive/data/FaceData/test')         # Define path for data\n",
        "\n",
        "\n",
        "def path_produce(premiere_path,emotion_path):\n",
        "  y = premiere_path/emotion_path\n",
        "  return y\n",
        "emotion = [\"angry\", \"disgusted\", \"fearful\", \"happy\",\"neutral\", \"sad\", \"surprised\"]\n",
        "emotion_number = [\"0\", \"1\", \"2\", \"3\",\"4\", \"5\", \"6\"]\n",
        "\n",
        "\n",
        "def get_images(images_path): \n",
        "  return images_path.glob('*.png')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_path_give_images(path,emotion,emotion_number):\n",
        "  all_data = pd.DataFrame(columns=['image' , 'emotionclass'],index=None)\n",
        "  j=0;\n",
        "  for i in emotion:\n",
        "    EmPath = path_produce(path, i)\n",
        "    array_images  = get_images(EmPath) \n",
        "    data = pd.DataFrame(array_images, columns=['image'],index=None)\n",
        "    data['emotionclass'] = emotion_number[j]\n",
        "    j+=1\n",
        "    d=[all_data,data]\n",
        "    all_data = pd.concat(d)\n",
        "  return all_data\n",
        "\n",
        "# Get data from paths\n",
        "all_train_data = get_path_give_images(data_train_path,emotion,emotion_number)\n",
        "all_test_data = get_path_give_images(data_test_path,emotion,emotion_number)\n",
        "\n",
        "# Shuffle data\n",
        "train_data = all_train_data.sample(frac=1.).reset_index(drop=True)\n",
        "test_data = all_test_data.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "X = train_data.image;\n",
        "y = train_data.emotionclass;\n",
        "\n",
        "\n",
        "X_val, X_train, y_val , y_train = train_test_split(X, y, test_size=0.9, random_state=1)\n",
        "df1 = {'image': X_train, 'emotionclass': y_train}\n",
        "train_data = pd.DataFrame(df1,index=None)\n",
        "\n",
        "df2 = {'image': X_val, 'emotionclass': y_val}\n",
        "validation_data = pd.DataFrame(df2,index=None)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN4T8ZP8EufF",
        "outputId": "d87927f5-cc8c-4834-eb3c-349096e078fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "emotionclass\n",
              "0    3995\n",
              "1     436\n",
              "2    4097\n",
              "3    7215\n",
              "4    4965\n",
              "5    4830\n",
              "6    3171\n",
              "Name: emotionclass, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "all_train_data.groupby('emotionclass').emotionclass.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZKdCD-Vq0uQ",
        "outputId": "718ff6b5-bec9-472c-a524-88ddb67e8036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25839 validated image filenames belonging to 7 classes.\n",
            "Found 2870 validated image filenames belonging to 7 classes.\n",
            "Found 7178 validated image filenames belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "IMG_SIZE = 256  # Image size\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Preprocessing object\n",
        "idg = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "# Turn values to strings as a requirement for flow_from_dataframe\n",
        "train_data['image'] = train_data['image'].astype(\"string\")\n",
        "validation_data['image'] = validation_data['image'].astype(\"string\")\n",
        "test_data['image'] = test_data['image'].astype(\"string\")\n",
        "\n",
        "# Create train generator\n",
        "train_gen = idg.flow_from_dataframe(dataframe= train_data,\n",
        "                                         x_col = 'image',\n",
        "                                         y_col = 'emotionclass',\n",
        "                                         target_size = (48,48),\n",
        "                                         class_mode = 'categorical',\n",
        "                                         color_mode = 'grayscale',\n",
        "                                         batch_size = BATCH_SIZE,\n",
        "                                         )\n",
        "\n",
        "# Create test generator\n",
        "validation_gen = idg.flow_from_dataframe(dataframe= validation_data, \n",
        "                                         x_col = 'image',\n",
        "                                         y_col = 'emotionclass',\n",
        "                                         target_size = (48,48),\n",
        "                                         class_mode = 'categorical',\n",
        "                                         color_mode = 'grayscale',\n",
        "                                         batch_size = BATCH_SIZE,\n",
        "                                         )\n",
        "# Create test generator\n",
        "test_gen = idg.flow_from_dataframe(dataframe= test_data, \n",
        "                                         x_col = 'image',\n",
        "                                         y_col = 'emotionclass',\n",
        "                                         target_size = (48,48),\n",
        "                                         class_mode = 'categorical',\n",
        "                                         color_mode = 'grayscale',\n",
        "                                         batch_size = BATCH_SIZE,\n",
        "                                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "0ac6gbSOJXZv"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Define CNN model\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "emotion_model = Sequential()\n",
        "\n",
        "# Block1\n",
        "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "emotion_model.add(BatchNormalization())\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "# emotion_model.add(BatchNormalization())\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# emotion_model.add(Dropout(0.2))\n",
        "\n",
        "# Block2\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "# emotion_model.add(BatchNormalization())\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "# emotion_model.add(BatchNormalization())\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# emotion_model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# Block4\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "# emotion_model.add(BatchNormalization())\n",
        "# emotion_model.add(Dropout(0.2))\n",
        "emotion_model.add(Dense(7, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6ggW_hj7IzA",
        "outputId": "da12a090-e9b9-413a-e3e0-7d48a055caf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "emotion_model.compile(loss='categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvKwy-a67JLa",
        "outputId": "53888204-9252-4920-a9a0-40b6207d8639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "50/50 [==============================] - 17s 319ms/step - loss: 1.8648 - accuracy: 0.2632 - val_loss: 1.9040 - val_accuracy: 0.2389\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 16s 311ms/step - loss: 1.5967 - accuracy: 0.3770 - val_loss: 1.8614 - val_accuracy: 0.3607\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 15s 305ms/step - loss: 1.4422 - accuracy: 0.4493 - val_loss: 1.8076 - val_accuracy: 0.3698\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 1.3454 - accuracy: 0.4879 - val_loss: 1.7946 - val_accuracy: 0.3750\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 1.2774 - accuracy: 0.5142 - val_loss: 1.7576 - val_accuracy: 0.4193\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 16s 318ms/step - loss: 1.2100 - accuracy: 0.5433 - val_loss: 1.6619 - val_accuracy: 0.4674\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 16s 318ms/step - loss: 1.1629 - accuracy: 0.5627 - val_loss: 1.5926 - val_accuracy: 0.4824\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 16s 325ms/step - loss: 1.0951 - accuracy: 0.5914 - val_loss: 1.4663 - val_accuracy: 0.5156\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 16s 312ms/step - loss: 1.0550 - accuracy: 0.6027 - val_loss: 1.4049 - val_accuracy: 0.5384\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 16s 311ms/step - loss: 1.0036 - accuracy: 0.6255 - val_loss: 1.3106 - val_accuracy: 0.5254\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 16s 312ms/step - loss: 0.9410 - accuracy: 0.6593 - val_loss: 1.2409 - val_accuracy: 0.5410\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.8840 - accuracy: 0.6802 - val_loss: 1.1988 - val_accuracy: 0.5547\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.8191 - accuracy: 0.7033 - val_loss: 1.1648 - val_accuracy: 0.5430\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 15s 305ms/step - loss: 0.7297 - accuracy: 0.7415 - val_loss: 1.2206 - val_accuracy: 0.5501\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 16s 310ms/step - loss: 0.6578 - accuracy: 0.7654 - val_loss: 1.2608 - val_accuracy: 0.5560\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 16s 312ms/step - loss: 0.5928 - accuracy: 0.7943 - val_loss: 1.2525 - val_accuracy: 0.5781\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 16s 309ms/step - loss: 0.5188 - accuracy: 0.8277 - val_loss: 1.4614 - val_accuracy: 0.5299\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 16s 310ms/step - loss: 0.4347 - accuracy: 0.8506 - val_loss: 1.5101 - val_accuracy: 0.5671\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.3735 - accuracy: 0.8772 - val_loss: 1.6405 - val_accuracy: 0.5534\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 16s 312ms/step - loss: 0.3075 - accuracy: 0.8983 - val_loss: 1.7322 - val_accuracy: 0.5736\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 15s 307ms/step - loss: 0.2732 - accuracy: 0.9110 - val_loss: 1.8600 - val_accuracy: 0.5547\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 16s 311ms/step - loss: 0.2428 - accuracy: 0.9252 - val_loss: 2.0196 - val_accuracy: 0.5371\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 16s 312ms/step - loss: 0.1861 - accuracy: 0.9427 - val_loss: 2.2687 - val_accuracy: 0.5553\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 15s 306ms/step - loss: 0.1668 - accuracy: 0.9501 - val_loss: 2.2473 - val_accuracy: 0.5632\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 15s 306ms/step - loss: 0.1469 - accuracy: 0.9568 - val_loss: 2.3692 - val_accuracy: 0.5684\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 16s 317ms/step - loss: 0.1225 - accuracy: 0.9629 - val_loss: 2.3829 - val_accuracy: 0.5592\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.1198 - accuracy: 0.9645 - val_loss: 2.6269 - val_accuracy: 0.5605\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.1040 - accuracy: 0.9712 - val_loss: 2.5503 - val_accuracy: 0.5775\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0920 - accuracy: 0.9727 - val_loss: 2.4079 - val_accuracy: 0.5736\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0854 - accuracy: 0.9754 - val_loss: 2.7278 - val_accuracy: 0.5592\n"
          ]
        }
      ],
      "source": [
        "#Train Model\n",
        "# from keras.models import load_model\n",
        "\n",
        "# TRAINING = True\n",
        "NUM_EPOCHS = 30\n",
        "# model_path = '/content/drive/MyDrive/Project_Colab/Pneumonia_detection/my_model.h5'\n",
        "\n",
        "# if TRAINING:\n",
        "# emotion_model_info = emotion_model.fit_generator(train_gen, \n",
        "#                                         epochs=NUM_EPOCHS, \n",
        "#                                         steps_per_epoch=None,\n",
        "#                                         validation_data=validation_gen,\n",
        "#                                         validation_steps=len(validation_gen))\n",
        "\n",
        "emotion_model_info = emotion_model.fit(\n",
        "        train_gen,\n",
        "        steps_per_epoch=len(train_gen)//2,\n",
        "        epochs=NUM_EPOCHS,\n",
        "        validation_data=validation_gen,\n",
        "        validation_steps=len(validation_gen)//2)\n",
        "   \n",
        "# else:\n",
        "\n",
        "  # returns a compiled model\n",
        "  # identical to the previous one\n",
        "  # model = load_model(model_path, compile=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "HRoDlGTeki_Y"
      },
      "outputs": [],
      "source": [
        "# predict test data\n",
        "num_test_batchs = len(iter(test_gen))\n",
        "\n",
        "pred_list = []\n",
        "label_list = []\n",
        "\n",
        "for i in range(num_test_batchs):\n",
        "  image, label = test_gen[i]\n",
        "  out_model = emotion_model.predict(\n",
        "    image, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,\n",
        "    workers=1\n",
        "    )\n",
        "  pred = tf.math.greater(out_model, 0.25, name=None)\n",
        "  pred_ = tf.dtypes.cast(pred, tf.int32)\n",
        "  pred_list.append(pred_)\n",
        "  label_list.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgtuALmBI-sT",
        "outputId": "ee4c632b-eae5-4cb1-e181-87d6c326ebbf"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.85024667e-07, 9.41863580e-16, 1.37478366e-07, 4.10564971e-05,\n",
              "        9.99934912e-01, 2.31178619e-05, 1.79220960e-09],\n",
              "       [9.99059618e-01, 2.35499738e-05, 8.56914907e-04, 5.72191175e-06,\n",
              "        9.63712955e-06, 3.26627378e-05, 1.18548105e-05],\n",
              "       [1.08728716e-04, 5.46257007e-12, 2.52455589e-04, 6.57899245e-13,\n",
              "        3.72752245e-03, 9.95911360e-01, 1.63603930e-09],\n",
              "       [4.55349655e-04, 1.20028830e-07, 9.66539383e-01, 1.78569257e-02,\n",
              "        6.84433462e-06, 1.61701319e-04, 1.49796642e-02],\n",
              "       [2.34723699e-13, 4.03686986e-24, 7.17456317e-07, 7.46288197e-06,\n",
              "        1.85606463e-04, 9.99806225e-01, 1.71379647e-10],\n",
              "       [7.39901404e-11, 8.31267672e-13, 8.83622168e-12, 5.33264415e-15,\n",
              "        8.56255267e-18, 7.36446928e-13, 1.00000000e+00],\n",
              "       [2.27521081e-03, 1.79301537e-06, 1.48523524e-01, 1.06665688e-02,\n",
              "        1.38896480e-02, 8.22471142e-01, 2.17206730e-03],\n",
              "       [4.42705071e-03, 2.94305980e-01, 1.18316861e-03, 3.38081081e-05,\n",
              "        1.10743269e-02, 6.88547194e-01, 4.28448839e-04],\n",
              "       [1.09371072e-07, 1.09372157e-10, 9.99942064e-01, 1.69135561e-07,\n",
              "        2.52044310e-06, 5.50430086e-05, 1.20084422e-07],\n",
              "       [1.02087961e-06, 7.67763026e-07, 5.95283648e-03, 3.78080500e-07,\n",
              "        6.47727529e-06, 1.41172316e-02, 9.79921222e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find y_test\n",
        "t = pd.DataFrame(np.array((label_list)))\n",
        "y_test = pd.DataFrame([])\n",
        "tt= np.asarray(t).flatten()\n",
        "for i in range(num_test_batchs):\n",
        "  ttt = np.reshape(tt[i], (-1,7))\n",
        "  y_test = y_test.append(pd.DataFrame(ttt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qzl_CbJ3oRp",
        "outputId": "5162ccb5-c0c2-493e-ba22-fb01b3958364"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find y_prediction\n",
        "\n",
        "pred_ = pd.DataFrame(np.array((pred_list)))\n",
        "y_predict = pd.DataFrame([])\n",
        "pp= np.asarray(pred_).flatten()\n",
        "for i in range(num_test_batchs):\n",
        "  ppp = np.reshape(pp[i], (-1,7))\n",
        "  y_predict = y_predict.append(pd.DataFrame(ppp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aAvHOWyWT7W",
        "outputId": "5575aac2-c2b6-4b8d-a2f2-71c39bb2c930"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "SPaf9kvnBBHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ac4359-0f2a-4575-f909-276d5753ff58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[5789  431]\n",
            "  [ 521  437]]\n",
            "\n",
            " [[6994   73]\n",
            "  [  52   59]]\n",
            "\n",
            " [[5410  744]\n",
            "  [ 575  449]]\n",
            "\n",
            " [[4900  504]\n",
            "  [ 327 1447]]\n",
            "\n",
            " [[5098  847]\n",
            "  [ 522  711]]\n",
            "\n",
            " [[4801 1130]\n",
            "  [ 540  707]]\n",
            "\n",
            " [[6112  235]\n",
            "  [ 231  600]]]\n",
            "Accuracy 0.5104485929228197\n",
            "F1_Score 0.5477830788428486\n",
            "Precision: 0.5183203962117817\n",
            "recall 0.5867803229250697\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Result\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score,precision_score,recall_score\n",
        "# print(\"confusion_matrix\", confusion_matrix(y_test,y_predict))\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "print(multilabel_confusion_matrix(y_test, y_predict))\n",
        "print(\"Accuracy\", accuracy_score(y_test, y_predict))\n",
        "print(\"F1_Score\", f1_score(y_test,y_predict, average = 'macro'))\n",
        "print(\"Precision:\",precision_score(y_test, y_predict,average='macro'))\n",
        "print(\"recall\",recall_score(y_test, y_predict,average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ALRgQnQTMYjq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "FaceEmotionRecognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}