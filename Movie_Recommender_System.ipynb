{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Recommender System\n",
        "\n",
        "## Overview\n",
        "\n",
        "This project develops a basic recommender system using collaborative filtering with the Python library `surprise`. The goal of the system is to recommend movies to users based on their past preferences and the preferences of other users with similar tastes.\n",
        "\n",
        "## System Architecture\n",
        "\n",
        "The recommender system follows these key steps:\n",
        "\n",
        "1. **Data Loading and Preparation**:\n",
        "    - The data used is the MovieLens 100K dataset which contains 100,000 movie ratings from users.\n",
        "    - The dataset is split into training and testing sets to evaluate the model's performance.\n",
        "\n",
        "2. **Model Building**:\n",
        "    - The system utilizes the Singular Value Decomposition (SVD) algorithm, a popular method for collaborative filtering on movie rating data.\n",
        "    - SVD is advantageous as it works well with sparse datasets and helps in identifying latent factors in the data.\n",
        "\n",
        "3. **Model Evaluation**:\n",
        "    - The model is evaluated using root mean square error (RMSE) to measure the accuracy of the predicted ratings.\n",
        "    - Cross-validation is used to ensure the model's robustness and to prevent overfitting.\n",
        "\n",
        "4. **Recommendations**:\n",
        "    - The model predicts ratings for user-item pairs that are not present in the training set.\n",
        "    - It also recommends a list of top N movies for each user based on the estimated ratings.\n",
        "\n",
        "## Technologies Used\n",
        "\n",
        "- **Python**: The primary programming language used.\n",
        "- **Surprise**: A Python scikit for building and analyzing recommender systems that deal with explicit rating data.\n",
        "\n",
        "## Setup and Installation\n",
        "\n",
        "To run this project, you need to install the required Python libraries. If you are using Google Colab, you can install `surprise` by running the following code cell:\n",
        "\n",
        "```python\n",
        "!pip install scikit-surprise\n"
      ],
      "metadata": {
        "id": "INLwESodyrpH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjnS0tBPyO9k",
        "outputId": "14e6f90a-f855-4adb-b387-9e414d3b301d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3162994 sha256=249913ad4c3a7e4bf3bfeeb8c29e2b77a0a1411fd574afbf2265ae74be0d73d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-surprise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD, Dataset, Reader, accuracy\n",
        "from surprise.model_selection import cross_validate, train_test_split\n",
        "\n",
        "# Step 1: Data Loading\n",
        "# Load the movielens-100k dataset (small dataset)\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# Step 2: Build the Collaborative Filtering Model\n",
        "model = SVD()\n",
        "\n",
        "# Step 3: Train the model on the trainset and predict ratings for the testset\n",
        "model.fit(trainset)\n",
        "predictions = model.test(testset)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy.rmse(predictions)\n",
        "\n",
        "# Step 4: Making Recommendations\n",
        "# Predicting rating for a specific user and item\n",
        "user_id = '196'  # raw user id\n",
        "item_id = '302'  # raw item id\n",
        "actual_rating = 4  # this is optional, just for comparison\n",
        "\n",
        "# Predict rating\n",
        "prediction = model.predict(user_id, item_id, r_ui=actual_rating, verbose=True)\n",
        "\n",
        "# Making top N recommendations for a user\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_top_n(predictions, n=10):\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the n highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n",
        "top_n = get_top_n(predictions, n=10)\n",
        "# Print the recommended items for user '196'\n",
        "print(top_n['196'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQuvgMO-ySg3",
        "outputId": "bd00a6ec-aa46-4b7b-e2bf-ec9ee81fc30c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "RMSE: 0.9341\n",
            "user: 196        item: 302        r_ui = 4.00   est = 4.13   {'was_impossible': False}\n",
            "[('8', 4.08871387884915), ('428', 3.916689368629527), ('393', 3.6876421471318106), ('66', 3.5124104587608866), ('381', 3.461086689138524), ('108', 3.2496598300989197), ('692', 3.249582094219165)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W3CNUMC6yWJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}